---
title: 'An RMPFR Tutorial (Arbitrary Precision Probability Densities) '
author: Matthew Parker
date: '2018-12-12'
slug: an-mpfr-tutorial-arbitrary-precision-probability-densities
categories:
  - R
  - Probability
tags:
  - R
  - arbitrary precision arithmetic
header:
  caption: ''
  image: ''
---



<div id="summary" class="section level2">
<h2>Summary</h2>
<p>Working on a likelihood function that relies on the Poisson distribution with large mean <span class="math inline">\(\lambda\)</span>, I ran into the problem of underflow! Underflow occurs when a number is too small to be stored in memory, and so it is truncated to be equal to zero. In my case, the probabilities are so small in the tails of the distribution, that the probabilities return as 0 (although there is a non-zero probability in those tails). This may not seem like a problem (close to zero is basically zero right?), however, when you are running an optimizer such as <tt>optim</tt>, the optimizer can get stuck in the tails of the distribution, where a flat likelihood prevents any updates to the parameters from occuring.</p>
</div>
<div id="the-problem" class="section level2">
<h2>The Problem</h2>
<p>Let’s take a look at the Poisson distribution for increasing <span class="math inline">\(\lambda\)</span>.</p>
<pre class="r"><code>x1 &lt;- 0:20
y1 &lt;- dpois(x = x1, lambda = 10)
x2 &lt;- 50:150
y2 &lt;- dpois(x = x2, lambda = 100)
x3 &lt;- 500:1500
y3 &lt;- dpois(x = x3, lambda = 1000)
x4 &lt;- 8000:12000
y4 &lt;- dpois(x = x4, lambda = 10000)

df &lt;- data.frame(x=c(x1,x2,x3,x4), Density=c(y1,y2,y3,y4), nam=c(rep(&quot;Lambda=10&quot;,times=length(x1)), rep(&quot;Lambda=100&quot;,times=length(x2)), rep(&quot;Lambda=1000&quot;,times=length(x3)), rep(&quot;Lambda=10000&quot;,times=length(x4))))

ggplot(data=df) + geom_line(aes(x = x, y = Density)) + facet_grid(cols = vars(nam), scales = &quot;free_x&quot;) + theme_bw()</code></pre>
<p><img src="/post/2018-12-12-an-mpfr-tutorial-arbitrary-precision-probability-densities_files/figure-html/couple-of-poisson-1.png" width="960" /></p>
<p>Now suppose we are looking at the x values which are 10% different from the mean (x<span class="math inline">\(=0.9*\lambda\)</span>)</p>
<pre class="r"><code># lamda values
lam &lt;- c(10,100,1000,10000, 100000)
# probabilities of observing exactly the quantiles
p &lt;- dpois(x = lam*0.90, lambda = lam)
options(scipen=10)
knitr::kable(x = data.frame(Lambda=lam, Quantile=0.90*lam, Probability=p), digits = 10, align=&#39;l&#39;)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Lambda</th>
<th align="left">Quantile</th>
<th align="left">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">10</td>
<td align="left">9</td>
<td align="left">0.1251100357</td>
</tr>
<tr class="even">
<td align="left">100</td>
<td align="left">90</td>
<td align="left">0.0250389446</td>
</tr>
<tr class="odd">
<td align="left">1000</td>
<td align="left">900</td>
<td align="left">0.0000751695</td>
</tr>
<tr class="even">
<td align="left">10000</td>
<td align="left">9000</td>
<td align="left">0.0000000000</td>
</tr>
<tr class="odd">
<td align="left">100000</td>
<td align="left">90000</td>
<td align="left">0.0000000000</td>
</tr>
</tbody>
</table>
<pre class="r"><code>options(scipen=0)</code></pre>
<p>You can see that as <span class="math inline">\(\lambda\)</span> increases in size, the probability of observations only slightly smaller than the mean are approaching very close to zero. This means that when you are running an optimizer, any observations in the tails of the distribution will return likelihoods of zero.</p>
</div>
<div id="libraries" class="section level2">
<h2>Libraries</h2>
<p>One solution to this is to use Arbitrary Precision Arithmetic (APA). Essentially we want to capture the non-zero probabilities even when they are too small for the computer to store as a single number. To accomplish this we will use the library <tt>Rmpfr</tt> to do APA.</p>
<pre class="r"><code>install.packages(&quot;Rmpfr&quot;)
library(Rmpfr)</code></pre>
<div id="rmpfr-basics" class="section level3">
<h3>Rmpfr Basics</h3>
<p>Let’s create an Arbitrary Precision Arithmetic number:</p>
<pre class="r"><code>num &lt;- mpfr(5, precBits = 100)
print(num)</code></pre>
<pre><code>## 1 &#39;mpfr&#39; number of precision  100   bits 
## [1] 5</code></pre>
<p>Okay, that’s not very useful, the number 5 doesn’t need arbitrary precision. Let’s try a very small number:</p>
<pre class="r"><code>(paste0(&quot;Regular R Arithmetic: &quot;,1/(5^1000)))</code></pre>
<pre><code>## [1] &quot;Regular R Arithmetic: 0&quot;</code></pre>
<pre class="r"><code>num2 &lt;- 1/(num^1000) 
(paste0(&quot;Arbitrary Precision Arithmetic: &quot;,format(num2)))</code></pre>
<pre><code>## [1] &quot;Arbitrary Precision Arithmetic: 1.071508607186267320948425049059e-699&quot;</code></pre>
</div>
</div>
<div id="arbitrary-precision-poisson-distribution" class="section level2">
<h2>Arbitrary Precision Poisson Distribution</h2>
<p>Now we need to create a function that calculates the Poisson density for arbitrary precision.</p>
<pre class="r"><code>dpois_apa &lt;- function(x, lambda, prec) {
  # create arbitrary precision arithmetic numbers
  x_apa &lt;- mpfr(x, precBits = prec)
  lambda_apa &lt;- mpfr(lambda, precBits = prec)
  # calculate the density
  dens &lt;- exp(-1*lambda_apa)*lambda_apa^(x_apa)/factorial(x_apa)
  return(dens)
}</code></pre>
<p>Let’s compare this with the regular <tt>dpois</tt> function:</p>
<pre class="r"><code>sum(dpois(x = 0:100, lambda = 900))</code></pre>
<pre><code>## [1] 4.368159e-254</code></pre>
<pre class="r"><code>sum(dpois_apa(x = 0:100, lambda = 900, prec = 100))</code></pre>
<pre><code>## 1 &#39;mpfr&#39; number of precision  100   bits 
## [1] 4.368158972674260090678233034232e-254</code></pre>
<p>Looks good, now let’s try with larger lambda (where we have been running into the underflow issue):</p>
<pre class="r"><code>sum(dpois(x = 0:1000, lambda = 10000))</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>sum(dpois_apa(x = 0:1000, lambda = 10000, prec = 100))</code></pre>
<pre><code>## 1 &#39;mpfr&#39; number of precision  100   bits 
## [1] 3.135370556023817217405692086175e-2911</code></pre>
</div>
<div id="usage-with-optim" class="section level2">
<h2>Usage With Optim</h2>
<p>Rmpfr class objects are not normal numerical objects (you may have noticed that to print the number nicely earlier I had to use <tt>print(format(num2))</tt> rather than the usual <tt>print(num2)</tt>). Because of this we can’t directly use them with the function <tt>optim</tt>. Luckily the package Rmpfr does contain a single-variable version called <tt>optimizeR</tt>. That will work for this example, however it won’t be sufficient if you have multiple variables to optimize over.</p>
<p>Here we generate some data, and write two likelihood functions, one with APA, and one without:</p>
<pre class="r"><code># 100 regular observations from a poisson with large lambda,
# plus one outlier at x=100
x &lt;- c(rpois(n = 100, lambda = 10000), 100)

# likelihood function with arbitrary precision arithmetic
L_apa &lt;- function(lambda, obs, prec=100) {
  return(prod(dpois_apa(x = obs, lambda = lambda, prec = prec)))
}

# likelihood function with regular R arithmetic
L &lt;- function(lambda, obs) {
  return(prod(dpois(x = obs, lambda = lambda)))
}</code></pre>
<p>Now we will try to optimize the two likelihoods to estimate <span class="math inline">\(\lambda\)</span>:</p>
<pre class="r"><code># regular optim
optim(par=c(10000), fn = L, method=&quot;Brent&quot;, lower=0, upper=100000, obs=x)</code></pre>
<pre><code>## $par
## [1] 1e+05
## 
## $value
## [1] 0
## 
## $counts
## function gradient 
##       NA       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<pre class="r"><code># Rmpfr optimizeR
optimizeR(f = L_apa, lower = 0, upper = 100000, method = &quot;Brent&quot;, obs=x)</code></pre>
<pre><code>## $minimum
## 1 &#39;mpfr&#39; number of precision  132   bits 
## [1] 99999.9999999999999989509571426832067835
## 
## $objective
## 1 &#39;mpfr&#39; number of precision  100   bits 
## [1] 1.506406340107169931008831319321e-2952462
## 
## $iter
## [1] 432
## 
## $convergence
## [1] TRUE
## 
## $estim.prec
## 1 &#39;mpfr&#39; number of precision  132   bits 
## [1] 1.024523095325062570397351721535880869084e-15
## 
## $method
## [1] &quot;Brent&quot;</code></pre>
<p>Interpreting the results above, regular <tt>optim</tt> was unable to converge, while the <tt>optimizeR</tt> gives an estimate of 99999.99…, which rounds to 10000. Since we generated the data ourselves, we know that the true value of <span class="math inline">\(\lambda\)</span> is actually 10000, so we have successfully optimized the likelihood with arbitrary precision arithmetic.</p>
</div>
