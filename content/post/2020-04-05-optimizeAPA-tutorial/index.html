---
title: 'optimizeAPA Tutorial (Arbitrary Precision Optimization)'
author: Matthew Parker
date: '2020-04-05'
categories:
  - R
  - Optimization
tags:
  - R
  - arbitrary precision arithmetic
  - arbitrary precision optimization
  - multiparameter
  - Rmpfr
  - optimization
  - tutorial
image:
  placement: 1
  focal_point: "Left"
  preview_only: false

disable_codefolding: false
---



<p><tt>optimizeAPA</tt> is an R package which allows for multi-parameter optimization. That means you can use it to find the maximum (or the minimum) value of a function with many input values. What makes <tt>optimizeAPA</tt> unique? It works with arbitrary precision arithmetic.</p>
<div id="why-use-optimizeapa" class="section level2">
<h2>Why use <tt>optimizeAPA</tt>?</h2>
<ul>
<li><a href="#apa-and-napa">1)</a> works with both <strong>APA</strong> and <strong>NAPA</strong> optimization</li>
<li><a href="#single-and-multi-parameter">2)</a> works with both <strong>single parameter</strong> and <strong>multi-parameter</strong> functions</li>
<li><a href="#save-an-output-file">3)</a> save an <strong>output file</strong> at each iteration</li>
<li><a href="#keep-values">4)</a> allows you to <strong>keep every value</strong> and input visited</li>
<li><a href="#plot-convergence">5)</a> easily <strong>plot the convergence path</strong> with a single function call</li>
</ul>
<p><i><strong>Note</strong>: APA stands for “arbitrary precision arithmetic”, while NAPA stands for “non arbitrary precision arithmetic”</i></p>
<div id="apa-and-napa" class="section level3">
<h3>APA and NAPA</h3>
<p>Using one package for both your APA and NAPA optimization can make troubleshooting and problem solving much easier. You can check the math and logic of your function without arbitrary precision first, and then implement the same function with arbitrary precision. The two functions you will want to use for optimization are <tt>optimizeAPA::optim_DFP_NAPA()</tt> and <tt>optimizeAPA::optim_DFP_APA()</tt>. DFP stands for <a href="https://en.wikipedia.org/wiki/Davidon%E2%80%93Fletcher%E2%80%93Powell_formula">“Davidon-Fletcher-Powell”</a>, and is the only optimization algorithm implemented in the <tt>optimizeAPA</tt> package (at the time of writing anyways).</p>
</div>
<div id="single-and-multi-parameter" class="section level3">
<h3>Single and Multi-parameter</h3>
<p>Other options exist for single parameter optimization (for example <a href="../2018-12-12-rmpfr-tutorial#usage-with-optim">Rmpfr::optimizeR()</a>), however, with <tt>optimizeAPA</tt> you can use the same functions for both single and multi-parameter function optimization. This saves you formatting your data and function multiple times for the various standards and formats employed by different packages.</p>
</div>
<div id="save-an-output-file" class="section level3">
<h3>Save an Output File</h3>
<p>Suppose you are not sure if your function will converge within the given number of iterations (the default is <tt>maxSteps=100</tt>). Then you can save an output file by setting <tt>outFile=“output_filename.csv”</tt>. This can then be used to give better starting values for a second run of the algorithm.</p>
<pre class="r"><code>optimizeAPA::optim_DFP_APA(starts,func,outFile=&quot;output_filename.csv&quot;,maxSteps=10)</code></pre>
</div>
<div id="keep-values" class="section level3">
<h3>Keep Values</h3>
<p>By setting <tt>keepValues=T</tt> in the function call, you can tell the optimization algorithm that you are interested in more than just the last visited function inputs and function value. For example:</p>
<pre class="r"><code>optimizeAPA::optim_DFP_APA(starts,func,keepValues = T)</code></pre>
<p>There are many reasons why you might want to do this, such as looking for convergence issues, determining better stopping criteria for future simulations (eg: by setting <tt>tolerance=10^-3</tt>), etc.</p>
<pre class="r"><code>optimizeAPA::optim_DFP_APA(starts,func,tolerance=10^-3)</code></pre>
<p><i><strong>Note</strong>: the default maximum number of iterations to save when </i><tt>keepValues=T</tt><i> is 100, if you want to keep every value, then set </i><tt>Memory=X</tt><i>, where </i><tt>X</tt><i> is equal to the number you have set for </i><tt>maxSteps</tt><i>.</i></p>
</div>
<div id="plot-convergence" class="section level3">
<h3>Plot Convergence</h3>
<p>When you set <tt>keepValues=T</tt>, you can make use of a helper function called <tt>optimizeAPA::plotConvergence()</tt>. This allows you to view the convergence paths of each input parameter. This can be a very useful visual diagnostic tool.</p>
<pre class="r"><code>op &lt;- optimizeAPA::optim_DFP_APA(starts,func,keepValues = T)
optimizeAPA::plotConvergence(op)</code></pre>
</div>
</div>
<div id="rmpfr" class="section level2">
<h2>Rmpfr</h2>
<p>I have covered the R package <tt>Rmpfr</tt> <a href="../2018-12-12-rmpfr-tutorial">previously</a>, and you may want to read up on <a href="https://CRAN.R-project.org/package=Rmpfr">the package</a> if you are interested in writing your own functions to optimize. I will give you a few examples <a href="#examples">here</a>, which you should be able to modify for your own needs.</p>
</div>
<div id="install-optimizeapa" class="section level2">
<h2>Install <tt>optimizeAPA</tt></h2>
<p><tt>optimizeAPA</tt> is available on <a href="https://github.com/mrparker909/optimizeAPA">github</a>, and can be installed using the <tt>remotes</tt> <a href="https://remotes.r-lib.org/">package</a>:</p>
<pre class="r"><code>remotes::install_github(&quot;mrparker909/optimizeAPA&quot;)</code></pre>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<p>For the folowing examples, we will use these libraries:</p>
<pre class="r"><code>library(ggplot2)
library(optimizeAPA)</code></pre>
<div id="single-parameter-function" class="section level3">
<h3>Single Parameter Function</h3>
<p>First, let’s define a regular function <tt>F1</tt> to optimize:</p>
<pre class="r"><code>F1 &lt;- function(par) {
  (1+par) * sin(2*(par-3)*pi) * exp(-(par-3)^4)
}</code></pre>
<p>Let’s plot the function, so we have some idea of what we’re looking at:</p>
<pre class="r"><code>x    = seq(0,6,0.01)
y    = sapply(X=x, FUN=F1)
dat1 = data.frame(x=x,y=y)

ggplot(data=dat1, aes(x=x,y=y)) + 
  geom_line() + 
  ggtitle(&quot;Plot of F1(x)&quot;) + 
  ylab(&quot;F1&quot;) + 
  theme_classic()</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-8"></span>
<img src="/post/2020-04-05-optimizeAPA-tutorial/index_files/figure-html/unnamed-chunk-8-1.png" alt="Plot of single parameter function." width="480" />
<p class="caption">
Figure 1: Plot of single parameter function.
</p>
</div>
<p>We want to find the maximum value <span class="math inline">\(F_0\)</span> of the function <tt>F1</tt>, and we want to know what input value <span class="math inline">\(x_0\)</span> gives us that maximum value. Since the algorithm searches for the minimum, we will input <span class="math inline">\(-F1\)</span> to find the maximum.</p>
<p>Notice that the maximum is somewhere between <span class="math inline">\(x=3\)</span> and <span class="math inline">\(x=4\)</span>, so let’s set <span class="math inline">\(x=3.5\)</span> as our starting value.</p>
<p>First, the NAPA version:</p>
<pre class="r"><code>F1neg = function(par) { -1*F1(par) }
op1 &lt;- optimizeAPA::optim_DFP_NAPA(starts=3.5, 
                                   func = F1neg, 
                                   keepValues = T, 
                                   tolerance=10^-3)</code></pre>
<p>Let’s look at the path to convergence:</p>
<pre class="r"><code>optimizeAPA::plotConvergence(op1)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-10"></span>
<img src="/post/2020-04-05-optimizeAPA-tutorial/index_files/figure-html/unnamed-chunk-10-1.png" alt="Plot of convergence for single parameter function F1 (NAPA)." width="576" />
<p class="caption">
Figure 2: Plot of convergence for single parameter function F1 (NAPA).
</p>
</div>
<p>So the maximum value of the function (found after 11 iterations of the algorithm) is <span class="math inline">\(F_0 = F1(3.2543) = 4.235\)</span>.</p>
<p>Now we will do the same thing but using arbitrary precision!</p>
<pre class="r"><code># note that precBits allows you to specify the number 
# of bits of precision in the calculation
F2 &lt;- function(par, precBits=53) {
  PI = Rmpfr::Const(&quot;pi&quot;, precBits)
  (1+par) * sin(2*(par-3)*PI) * exp(-(par-3)^4)
}</code></pre>
<p>Now, the APA optimization:</p>
<pre class="r"><code>F2neg = function(par, precBits) { -1*F2(par,precBits) }
op2 &lt;- optimizeAPA::optim_DFP_APA(starts=3.5, 
                                  func = F2neg, 
                                  keepValues = T, 
                                  tolerance=10^-3, 
                                  precBits = 64)</code></pre>
<p>Let’s look at the path to convergence:</p>
<pre class="r"><code>optimizeAPA::plotConvergence(op2)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-13"></span>
<img src="/post/2020-04-05-optimizeAPA-tutorial/index_files/figure-html/unnamed-chunk-13-1.png" alt="Plot of convergence for single parameter function F2 (APA)." width="576" />
<p class="caption">
Figure 3: Plot of convergence for single parameter function F2 (APA).
</p>
</div>
<p>So the convergence plots look the same, but let’s compare the values found by the two algorithms:</p>
<pre class="r"><code>knitr::kable(data.frame(algorithm = c(&quot;F1: NAPA&quot;,   &quot;F2: APA&quot;),
           F_0 = c(Rmpfr::format(-1*op1$f[[1]]),
                   Rmpfr::format(-1*op2$f[[1]])),
           x_0 = c(Rmpfr::format(op1$x[[1]]),    
                   Rmpfr::format(op2$x[[1]]))))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">algorithm</th>
<th align="left">F_0</th>
<th align="left">x_0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">F1: NAPA</td>
<td align="left">4.234999</td>
<td align="left">3.254283</td>
</tr>
<tr class="even">
<td align="left">F2: APA</td>
<td align="left">4.23499947119854843521</td>
<td align="left">3.25428303229783782188</td>
</tr>
</tbody>
</table>
<p>You can see that we only have 6 decimal places of precision from the NAPA algorithm (corresponding to 53 bits of precision), whereas the APA algorithm gave us 20 decimal places of precision (corresponding to the 64 bits of precision we chose when we set <tt>precBits=64</tt>).</p>
</div>
<div id="multi-parameter-function" class="section level3">
<h3>Multi-Parameter Function</h3>
<p>Functions of a single parameter are not nearly as exciting as functions with many inputs. Let’s augment our previous function <tt>F1</tt>, so that it takes two inputs.</p>
<pre class="r"><code># now par is a vector of length 2
F3 &lt;- function(par) {
  x = par[1]
  y = par[2]
  (1+x) * sin(2*(x-3)*pi) * exp(-(x-3)^4) *
    (2+y) * sin(2*(y-2)*pi) * exp(-(y-2)^4)
}</code></pre>
<pre class="r"><code># here we define an x,y coordinate grid, and we
# calculate z=F3(x,y) at each point of the grid
x = seq(1,5,length=50)
y = seq(0,4,length=50)
z = outer(x,y,FUN = Vectorize(function(x,y) { F3(par=c(x,y)) }))

par(mai=c(0.4,0,0.1,0))
persp(x,y,z,col=&quot;dodgerblue&quot;,border=&quot;navy&quot;,
      theta=30,phi=22,shade=0.75,
      xaxs=&quot;i&quot;,yaxs=&quot;i&quot;,
      ltheta=-55,lphi=30)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-16"></span>
<img src="/post/2020-04-05-optimizeAPA-tutorial/index_files/figure-html/unnamed-chunk-16-1.png" alt="Plot of multi-parameter function." width="672" />
<p class="caption">
Figure 4: Plot of multi-parameter function.
</p>
</div>
<p>Now let’s find the maximum value of <span class="math inline">\(F3\)</span>, and the pair of values <span class="math inline">\(x_0\)</span> and <span class="math inline">\(y_0\)</span> which maximize the function!</p>
<p>First, we need a good starting point, so let’s use the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> values which gave the largest <span class="math inline">\(z\)</span>:</p>
<pre class="r"><code>which(z==max(z), arr.ind = T)</code></pre>
<pre><code>##      row col
## [1,]  29  29</code></pre>
<p>So the starting values are <span class="math inline">\(x[29], y[29]\)</span> = (3.28571429,2.28571429)</p>
<pre class="r"><code>F3neg = function(par) { -1*F3(par) }
op3 &lt;- optimizeAPA::optim_DFP_NAPA(starts=c(x[29],y[29]), 
                                   func = F3neg, 
                                   keepValues = T, 
                                   tolerance=10^-3)</code></pre>
<p>Again we can look at the convergence plot:</p>
<pre class="r"><code># this time we disable the function labels for legibility
# using: labels = F
optimizeAPA::plotConvergence(op3, labels = F)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-19"></span>
<img src="/post/2020-04-05-optimizeAPA-tutorial/index_files/figure-html/unnamed-chunk-19-1.png" alt="Plot of convergence for multi-parameter function F3 (NAPA)." width="864" />
<p class="caption">
Figure 5: Plot of convergence for multi-parameter function F3 (NAPA).
</p>
</div>
<p>The algorithm converged after 33 iterations. We can get at the maximum function value and at the values of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> which jointly maximize the function:</p>
<pre class="r"><code>-1*op3$f[[1]] # note that we multiply by -1 to undo our previous transformation</code></pre>
<pre><code>## [1] 17.93522</code></pre>
<pre class="r"><code>op3$x[[1]]    # note that &quot;x&quot; here denotes c(x,y)</code></pre>
<pre><code>##          [,1]
## [1,] 3.254288
## [2,] 2.254288</code></pre>
<p>The maximum value of <span class="math inline">\(F3\)</span> is 17.9352205, and that value is attained by <span class="math inline">\(x=\)</span> 3.2542878, and <span class="math inline">\(y=\)</span> 2.2542877.</p>
<p>Let’s make <span class="math inline">\(F3\)</span> APA:</p>
<pre class="r"><code>F4 &lt;- function(par, precBits=53) {
  x = par[1]
  y = par[2]
  PI = Rmpfr::Const(&quot;pi&quot;, precBits)
  (1+x) * sin(2*(x-3)*PI) * exp(-(x-3)^4) *
    (2+y) * sin(2*(y-2)*PI) * exp(-(y-2)^4)
}</code></pre>
<pre class="r"><code>F4neg = function(par, precBits) { -1*F4(par, precBits) }
op4 &lt;- optimizeAPA::optim_DFP_APA(starts=c(x[29],y[29]), 
                                  func = F4neg, 
                                  keepValues = T, 
                                  tolerance=10^-3,
                                  precBits=120)</code></pre>
<p>This time the convergence plot is slightly different, and the convergence took 38 steps to achieve:</p>
<pre class="r"><code># this time we disable the function labels for legibility
# using: labels = F
optimizeAPA::plotConvergence(op4, labels = F)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-23"></span>
<img src="/post/2020-04-05-optimizeAPA-tutorial/index_files/figure-html/unnamed-chunk-23-1.png" alt="Plot of convergence for multi-parameter function F4 (APA)." width="864" />
<p class="caption">
Figure 6: Plot of convergence for multi-parameter function F4 (APA).
</p>
</div>
<pre class="r"><code>knitr::kable(data.frame(algorithm = c(&quot;F3: NAPA&quot;,   &quot;F4: APA&quot;),
           F_0 = c(Rmpfr::format(-1*op3$f[[1]]),
                   Rmpfr::format(-1*op4$f[[1]])),
           x_0 = c(Rmpfr::format(op3$x[[1]][1]),    
                   Rmpfr::format(op4$x[[1]][1])),
           y_0 = c(Rmpfr::format(op3$x[[1]][2]),    
                   Rmpfr::format(op4$x[[1]][2]))))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">algorithm</th>
<th align="left">F_0</th>
<th align="left">x_0</th>
<th align="left">y_0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">F3: NAPA</td>
<td align="left">17.93522</td>
<td align="left">3.254288</td>
<td align="left">2.254288</td>
</tr>
<tr class="even">
<td align="left">F4: APA</td>
<td align="left">17.935220532183663378291420336576143962</td>
<td align="left">3.2542876863244057572412360419991646041</td>
<td align="left">2.2542879503583251025434494774779739170</td>
</tr>
</tbody>
</table>
<p>Of course you can use these methods on functions of many more variables, just use <tt>par</tt> as a vector to hold each of the parameters to be optimized over.</p>
<p>As a word of caution, changing <tt>tolerance</tt> is essentially setting the accuracy of the optimization (where as changing <tt>precBits</tt> is setting the precision). This means that decreasing <tt>tolerance</tt> can improve the results of the algorithm, but be warned that it likely will also take more iterations to converge. Have a look at the gradient field of the optimization output for some idea of how close to the maximum (or minimum) the algorithm has gotten:</p>
<pre class="r"><code>op4$grad[[1]]</code></pre>
<pre><code>## 2 &#39;mpfr&#39; numbers of precision  120   bits 
## [1]     0.0004730224609375 0.00066280364990234375</code></pre>
<p>Note that the closer to zero each of the values in the gradient is, the closer the algorithm is to a local minimum or maximum.</p>
</div>
</div>
<div id="conclusions" class="section level2">
<h2>Conclusions</h2>
<p>There is a ton more that you can do with <tt>optimizeAPA</tt>, and the package is still being developed, so expect more in the future. You can have a look at the package <a href="https://github.com/mrparker909/optimizeAPA">README</a> for a few more examples.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p>Davidon, W. (1959). Variable metric method for minimization. Technical Report ANL-5990, 4252678.</p>
</div>
